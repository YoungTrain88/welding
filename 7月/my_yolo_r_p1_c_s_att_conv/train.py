# train.py

import os

import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim

# ----------------- 1. ä»è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æ‰€éœ€ç±» -----------------
# ç¡®ä¿å¯ä»¥ä»æˆ‘ä»¬åˆ›å»ºçš„æ¨¡å—ä¸­å¯¼å…¥ RegressionModel
from PIL import Image
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import transforms
from tqdm import tqdm

# ä» ultralytics å¯¼å…¥ YOLO ä»¥ä¾¿åŠ è½½æ¨¡å‹ç»“æ„å’Œæƒé‡
from ultralytics import YOLO

# ----------------- 2. å®šä¹‰è¶…å‚æ•°å’Œé…ç½® -----------------
# è·¯å¾„é…ç½®
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
MODEL_YAML_PATH = os.path.join(PROJECT_ROOT, "yolov8n-regression.yaml")
PRETRAINED_WEIGHTS_PATH = "yolov8n.pt"  # ç¡®ä¿æ­¤æ–‡ä»¶å·²ä¸‹è½½æˆ–å­˜åœ¨
TRAIN_CSV_PATH = os.path.join(PROJECT_ROOT, "datasets", "train.csv")
VAL_CSV_PATH = os.path.join(PROJECT_ROOT, "datasets", "val.csv")
SAVE_DIR = os.path.join(PROJECT_ROOT, "runs")  # ä¿å­˜æ¨¡å‹æƒé‡å’Œç»“æœçš„ç›®å½•

# è®­ç»ƒé…ç½®
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
EPOCHS = 50
BATCH_SIZE = 8
LEARNING_RATE = 1e-4
IMG_SIZE = 224

# ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
os.makedirs(SAVE_DIR, exist_ok=True)


# ----------------- 3. è‡ªå®šä¹‰æ•°æ®é›†ç±» -----------------
class RegressionDataset(Dataset):
    def __init__(self, csv_path, transform=None):
        self.data_frame = pd.read_csv(csv_path)
        self.transform = transform

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        img_relative_path = self.data_frame.iloc[idx, 0]
        img_abs_path = os.path.join(PROJECT_ROOT, img_relative_path)
        image = Image.open(img_abs_path).convert("RGB")

        value = torch.tensor([self.data_frame.iloc[idx, 1]], dtype=torch.float32)

        if self.transform:
            image = self.transform(image)
        return image, value


# ----------------- 4. ä¸»è®­ç»ƒé€»è¾‘ -----------------
def main():
    print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")

    # --- æ•°æ®åŠ è½½ ---
    transform = transforms.Compose(
        [
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    train_dataset = RegressionDataset(csv_path=TRAIN_CSV_PATH, transform=transform)
    val_dataset = RegressionDataset(csv_path=VAL_CSV_PATH, transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    print("æ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæ¯•ã€‚")

    # --- æ¨¡å‹åˆå§‹åŒ– ---
    # 1. ä½¿ç”¨YOLOç±»ä».yamlæ–‡ä»¶æ„å»ºæ¨¡å‹ç»“æ„
    # 2. .load()æ–¹æ³•åŠ è½½é¢„è®­ç»ƒçš„æƒé‡åˆ°è¿™ä¸ªç»“æ„ä¸­
    # 3. .model æå–å‡ºåº•å±‚çš„PyTorch nn.Module
    model_wrapper = YOLO(MODEL_YAML_PATH).load(PRETRAINED_WEIGHTS_PATH)
    net = model_wrapper.model.to(DEVICE)
    print("æ¨¡å‹åŠ è½½å¹¶ç§»åŠ¨åˆ°è®¾å¤‡ã€‚")

    # --- æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ---
    criterion = nn.MSELoss()  # å‡æ–¹è¯¯å·®æŸå¤±ï¼Œå›å½’ä»»åŠ¡é¦–é€‰
    # criterion = nn.L1Loss() # ä¹Ÿå¯ä½¿ç”¨L1æŸå¤± (å¹³å‡ç»å¯¹è¯¯å·®)
    optimizer = optim.AdamW(net.parameters(), lr=LEARNING_RATE)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # æ¯10ä¸ªepochå­¦ä¹ ç‡ä¹˜ä»¥0.5

    # --- è®­ç»ƒå¾ªç¯ ---
    best_val_loss = float("inf")

    for epoch in range(EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        net.train()
        running_loss = 0.0
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [è®­ç»ƒ]")

        for images, labels in train_pbar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = net(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            train_pbar.set_postfix({"loss": loss.item()})

        avg_train_loss = running_loss / len(train_loader)

        # éªŒè¯é˜¶æ®µ
        net.eval()
        val_loss = 0.0
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [éªŒè¯]")
            for images, labels in val_pbar:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = net(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                val_pbar.set_postfix({"val_loss": loss.item()})

        avg_val_loss = val_loss / len(val_loader)

        print(f"Epoch {epoch + 1}/{EPOCHS} -> è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | éªŒè¯æŸå¤±: {avg_val_loss:.4f}")

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()

        # --- ä¿å­˜æ¨¡å‹ ---
        # ä¿å­˜æœ€æ–°çš„æ¨¡å‹
        torch.save(net.state_dict(), os.path.join(SAVE_DIR, "last.pt"))

        # å¦‚æœéªŒè¯æŸå¤±åˆ›æ–°ä½ï¼Œåˆ™ä¿å­˜ä¸ºæœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(net.state_dict(), os.path.join(SAVE_DIR, "best.pt"))
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ŒéªŒè¯æŸå¤±: {best_val_loss:.4f}")

    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ°: {os.path.join(SAVE_DIR, 'best.pt')}")


if __name__ == "__main__":
    main()
