# train_yolo_multimodal_custom_dims.py

import glob
import os

import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
from sklearn.metrics import mean_absolute_error, r2_score
from torch.utils.data import DataLoader, Dataset
from torchinfo import summary
from torchvision.transforms import transforms
from tqdm import tqdm

# å¯¼å…¥æˆ‘ä»¬ä¹‹å‰é€‚é…å¥½çš„ã€å¯ä»¥è¿”å›ç‰¹å¾çš„RegressionModel
from yolo8_12_fb_all_net_MultiModal_dim.custom_modules.custom_tasks import RegressionModel

# ===================================================================
# 1. é…ç½® (ä¸æ‚¨æä¾›çš„ä»£ç ä¿æŒä¸€è‡´)
# ===================================================================
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
# ##################################################################
# ## (æ˜¾è‘—æ ‡è¯†) è¯·åŠ¡å¿…æ£€æŸ¥è¿™é‡Œçš„ PROJECT_NAME æ˜¯å¦ä¸æ‚¨çš„æ–‡ä»¶å¤¹åå®Œå…¨ä¸€è‡´ï¼##
# ## æ ¹æ®æ‚¨çš„æŠ¥é”™ä¿¡æ¯ï¼Œå®ƒåº”è¯¥æ˜¯ 'yolo8_12_f_all_net_MultiModal_dim'
# ##################################################################
PROJECT_NAME = "yolo8_12_fb_all_net_MultiModal_dim"
EPOCHS = 150
TRAIN_CSV_PATH = os.path.join(PROJECT_ROOT, PROJECT_NAME, "datasets", "train.csv")
VAL_CSV_PATH = os.path.join(PROJECT_ROOT, PROJECT_NAME, "datasets", "val.csv")

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 8
LEARNING_RATE = 1e-5
WEIGHT_DECAY = 1e-2  # ä¿æŒæ­£åˆ™åŒ–
IMG_SIZE = 224


# ===================================================================
# 2. æ•°æ®é›†ç±» (æ ¸å¿ƒä¿®æ­£å¤„)
# ===================================================================
class RegressionDataset(Dataset):
    def __init__(self, csv_path, project_root, project_name, transform=None):
        """åˆå§‹åŒ–å‡½æ•°ç°åœ¨ä¹Ÿæ¥æ”¶ project_nameï¼Œä»¥ç¡®ä¿è·¯å¾„æ‹¼æ¥æ­£ç¡®ã€‚."""
        self.data_frame = pd.read_csv(csv_path).dropna()
        self.transform = transform
        self.project_root = project_root
        self.project_name = project_name  # å­˜å‚¨é¡¹ç›®åç§°
        self.target_values = self.data_frame.iloc[:, 1].values.astype("float32")
        self.tabular_data = self.data_frame.iloc[:, 2:].values.astype("float32")
        self.image_paths = self.data_frame.iloc[:, 0].values
        self.num_tabular_features = self.tabular_data.shape[1]

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        img_relative_path = self.image_paths[idx].replace("\\", "/")

        # ##################################################################
        # ## (æ˜¾è‘—æ ‡è¯†) å…³é”®ä¿®æ­£: ä½¿ç”¨ project_name æ¥æ„å»ºæ­£ç¡®çš„ç»å¯¹è·¯å¾„ ##
        # ##################################################################
        img_abs_path = os.path.join(self.project_root, self.project_name, img_relative_path)

        try:
            image = Image.open(img_abs_path).convert("RGB")
        except FileNotFoundError:
            error_msg = (
                f"\n\n[æ–‡ä»¶æœªæ‰¾åˆ°é”™è¯¯!]\n"
                f"è¯•å›¾è®¿é—®çš„å›¾ç‰‡è·¯å¾„: {img_abs_path}\n"
                f"è¿™ä¸ªè·¯å¾„ç”±ä»¥ä¸‹ä¸‰éƒ¨åˆ†æ‹¼æ¥è€Œæˆ:\n"
                f"  1. è„šæœ¬æ ¹ç›®å½• (PROJECT_ROOT): {self.project_root}\n"
                f"  2. é¡¹ç›®æ–‡ä»¶å¤¹å (PROJECT_NAME): {self.project_name}\n"
                f"  3. ä»CSVè¯»åˆ°çš„ç›¸å¯¹è·¯å¾„: {img_relative_path}\n"
                f"è¯·æ£€æŸ¥:\n"
                f"  - æ‚¨çš„å›¾ç‰‡æ˜¯å¦çœŸçš„å­˜æ”¾åœ¨è¿™ä¸ªæœ€ç»ˆè·¯å¾„ä¸‹?\n"
                f"  - è„šæœ¬é¡¶éƒ¨çš„ PROJECT_NAME å˜é‡æ˜¯å¦ä¸æ‚¨çš„æ–‡ä»¶å¤¹åå®Œå…¨ä¸€è‡´?\n"
            )
            raise FileNotFoundError(error_msg)

        tabular_features = torch.tensor(self.tabular_data[idx], dtype=torch.float32)
        target_value = torch.tensor([self.target_values[idx]], dtype=torch.float32)

        if self.transform:
            image = self.transform(image)

        return image, tabular_features, target_value


# ===================================================================
# 3. å¤šæ¨¡æ€æ¨¡å‹å®šä¹‰ (ä¸ä¹‹å‰ç‰ˆæœ¬ä¸€è‡´)
# ===================================================================
class MultiModalModel(nn.Module):
    """ä¸€ä¸ªå¯ä»¥è‡ªå®šä¹‰è§†è§‰å’Œè¡¨æ ¼ç‰¹å¾ç»´åº¦çš„å¤šæ¨¡æ€YOLOæ¨¡å‹ã€‚."""

    def __init__(
        self, yaml_path, num_tabular_features, image_output_dim=8, tabular_output_dim=4, hidden_dim=64, dropout_rate=0.5
    ):
        super().__init__()

        self.image_branch = RegressionModel(yaml_path, ch=3, verbose=False)
        original_image_feature_dim = 1280

        self.image_feature_compressor = nn.Sequential(
            nn.Linear(original_image_feature_dim, image_output_dim), nn.ReLU()
        )

        self.tabular_branch = nn.Sequential(
            nn.Linear(num_tabular_features, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim, tabular_output_dim),
        )

        fusion_input_dim = image_output_dim + tabular_output_dim
        self.fusion_head = nn.Sequential(
            nn.Linear(fusion_input_dim, hidden_dim), nn.ReLU(), nn.Dropout(dropout_rate), nn.Linear(hidden_dim, 1)
        )

    def forward(self, image, tabular_data):
        original_image_features = self.image_branch(image, return_features=True)
        compressed_image_features = self.image_feature_compressor(original_image_features)
        tabular_features = self.tabular_branch(tabular_data)
        combined_features = torch.cat([compressed_image_features, tabular_features], dim=1)
        output = self.fusion_head(combined_features)
        return output


# ===================================================================
# 4. è®­ç»ƒå‡½æ•° (å·²ä¿®æ­£)
# ===================================================================
def train_one_yaml(yaml_path):
    print(f"\n========== å¼€å§‹è®­ç»ƒ: {yaml_path} ==========")
    yaml_name = os.path.splitext(os.path.basename(yaml_path))[0]
    save_dir = os.path.join(PROJECT_ROOT, PROJECT_NAME, f"runs-{yaml_name}")
    os.makedirs(save_dir, exist_ok=True)

    train_transform = transforms.Compose(
        [
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    val_transform = transforms.Compose(
        [
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    # ##################################################################
    # ## (æ˜¾è‘—æ ‡è¯†) å…³é”®ä¿®æ­£: åˆ›å»ºDatasetæ—¶ï¼Œä¼ å…¥PROJECT_NAME ##
    # ##################################################################
    train_dataset = RegressionDataset(
        csv_path=TRAIN_CSV_PATH, project_root=PROJECT_ROOT, project_name=PROJECT_NAME, transform=train_transform
    )
    val_dataset = RegressionDataset(
        csv_path=VAL_CSV_PATH, project_root=PROJECT_ROOT, project_name=PROJECT_NAME, transform=val_transform
    )

    num_tabular_features = train_dataset.num_tabular_features

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    print(f"æ£€æµ‹åˆ° {num_tabular_features} ä¸ªè¡¨æ ¼ç‰¹å¾ã€‚")

    net = MultiModalModel(
        yaml_path=yaml_path, num_tabular_features=num_tabular_features, image_output_dim=8, tabular_output_dim=4
    ).to(DEVICE)

    print("\n" + "=" * 50)
    print(f"             æ¨¡å‹ç»“æ„: {os.path.basename(yaml_path)}")
    print("=" * 50)
    summary(
        net,
        input_size=[(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), (BATCH_SIZE, num_tabular_features)],
        depth=3,
        col_names=["input_size", "output_size", "num_params", "mult_adds"],
    )
    print("=" * 50 + "\n")

    criterion = nn.MSELoss()
    optimizer = optim.AdamW(net.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, "min", patience=10, factor=0.5, verbose=True)

    best_val_loss = float("inf")
    train_losses, val_losses, val_maes, val_r2s = [], [], [], []

    for epoch in range(EPOCHS):
        net.train()
        running_loss = 0.0
        train_pbar = tqdm(train_loader, desc=f"[{yaml_name}] Epoch {epoch + 1}/{EPOCHS} [è®­ç»ƒ]")
        for images, tabular, labels in train_pbar:
            images, tabular, labels = images.to(DEVICE), tabular.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = net(images, tabular)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            train_pbar.set_postfix({"loss": loss.item()})
        avg_train_loss = running_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        net.eval()
        val_loss, all_preds, all_labels = 0.0, [], []
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"[{yaml_name}] Epoch {epoch + 1}/{EPOCHS} [éªŒè¯]")
            for images, tabular, labels in val_pbar:
                images, tabular, labels = images.to(DEVICE), tabular.to(DEVICE), labels.to(DEVICE)
                outputs = net(images, tabular)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                all_preds.extend(outputs.cpu().numpy().flatten())
                all_labels.extend(labels.cpu().numpy().flatten())
        avg_val_loss = val_loss / len(val_loader)
        val_mae = mean_absolute_error(all_labels, all_preds)
        val_r2 = r2_score(all_labels, all_preds)
        val_losses.append(avg_val_loss)
        val_maes.append(val_mae)
        val_r2s.append(val_r2)

        print(
            f"[{yaml_name}] Epoch {epoch + 1}/{EPOCHS} -> è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | éªŒè¯æŸå¤±: {avg_val_loss:.4f} | éªŒè¯MAE: {val_mae:.4f} | éªŒè¯R2: {val_r2:.4f}"
        )
        scheduler.step(avg_val_loss)
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(net.state_dict(), os.path.join(save_dir, "best.pt"))
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ŒéªŒè¯æŸå¤±: {best_val_loss:.4f}")

    print(f"\næ¨¡å‹ {yaml_name} è®­ç»ƒå®Œæˆï¼Œæ­£åœ¨ä¿å­˜æ—¥å¿—...")
    with open(os.path.join(save_dir, "train_losses.txt"), "w", encoding="utf-8") as f:
        for item in train_losses:
            f.write(f"{item}\n")
    with open(os.path.join(save_dir, "val_losses.txt"), "w", encoding="utf-8") as f:
        for item in val_losses:
            f.write(f"{item}\n")
    with open(os.path.join(save_dir, "val_maes.txt"), "w", encoding="utf-8") as f:
        for item in val_maes:
            f.write(f"{item}\n")
    with open(os.path.join(save_dir, "val_r2s.txt"), "w", encoding="utf-8") as f:
        for item in val_r2s:
            f.write(f"{item}\n")
    print("æ‰€æœ‰æ—¥å¿—å·²ä¿å­˜ã€‚")


# ===================================================================
# 5. ä¸»æ‰§è¡Œå™¨ (ä¸æ‚¨æä¾›çš„ä»£ç ä¿æŒä¸€è‡´)
# ===================================================================
if __name__ == "__main__":
    yaml_dir = os.path.join(PROJECT_ROOT, PROJECT_NAME, "yaml")
    yaml_files = glob.glob(os.path.join(yaml_dir, "*.yaml"))
    print(f"å…±æ£€æµ‹åˆ° {len(yaml_files)} ä¸ªyamlæ–‡ä»¶ï¼Œå°†ä¾æ¬¡è®­ç»ƒï¼š")
    for yaml_path in yaml_files:
        train_one_yaml(yaml_path)
