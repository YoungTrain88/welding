# run_experiments_multimodal_late_fusion.py

import os

import pandas as pd
import timm  # å¯¼å…¥timmåº“
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
from PIL import Image
from sklearn.metrics import mean_absolute_error, r2_score
from torch.utils.data import DataLoader, Dataset
from torchinfo import summary  # å¯¼å…¥torchinfoåº“ç”¨äºæ‰“å°æ¨¡å‹ç»“æ„
from torchvision.transforms import transforms
from tqdm import tqdm

# ===================================================================
# 1. å…¨å±€é…ç½®
# ===================================================================

# --- è¯·æ ¹æ®æ‚¨çš„é¡¹ç›®è·¯å¾„è¿›è¡Œä¿®æ”¹ ---
PROJECT_ROOT = r"C:\Users\User\Desktop\ç„Šæ¥\ultralytics-main\ultralytics-main\other_net_fb_MultiModal"
# å»ºè®®ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰ä¸ºè§£å†³æ•°æ®åˆ†å¸ƒé—®é¢˜è€Œé‡æ–°åˆ’åˆ†å¥½çš„æ•°æ®
TRAIN_CSV_PATH = os.path.join(PROJECT_ROOT, "datasets", "train.csv")
VAL_CSV_PATH = os.path.join(PROJECT_ROOT, "datasets", "val.csv")
# ---------------------------------

# --- è®­ç»ƒè¶…å‚æ•° ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
EPOCHS = 900  # å…ˆç”¨100è½®è§‚å¯Ÿè¶‹åŠ¿
BATCH_SIZE = 16
LEARNING_RATE = 1e-4
WEIGHT_DECAY = 1e-2  # åŠ å…¥æƒé‡è¡°å‡ä»¥å¯¹æŠ—è¿‡æ‹Ÿåˆ
IMG_SIZE = 224


# ===================================================================
# 2. å¤šæ¨¡æ€æ•°æ®é›†ç±» (å·²å‡çº§)
# ===================================================================
class MultiModalDataset(Dataset):
    """ä¸€ä¸ªå¯ä»¥åŒæ—¶å¤„ç†å›¾åƒå’Œå¤šåˆ—è¡¨æ ¼æ•°æ®çš„Datasetç±»ã€‚."""

    def __init__(self, csv_path, project_root, transform=None):
        self.data_frame = pd.read_csv(csv_path).dropna()  # åŠ è½½å¹¶ä¸¢å¼ƒç©ºè¡Œ
        self.transform = transform
        self.project_root = project_root

        # è‡ªåŠ¨è·å–ç›®æ ‡å€¼å’Œæ‰€æœ‰è¡¨æ ¼ç‰¹å¾
        self.target_values = self.data_frame.iloc[:, 1].values.astype("float32")
        self.tabular_data = self.data_frame.iloc[:, 2:].values.astype("float32")
        self.image_paths = self.data_frame.iloc[:, 0].values

        self.num_tabular_features = self.tabular_data.shape[1]

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        # --- ç¨³å¥çš„è·¯å¾„å¤„ç† ---
        img_relative_path = self.image_paths[idx].replace("\\", "/")
        img_abs_path = os.path.join(self.project_root, img_relative_path)

        try:
            image = Image.open(img_abs_path).convert("RGB")
        except FileNotFoundError:
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ–‡ä»¶ {img_abs_path}ï¼Œå°†è¿”å›ä¸€ä¸ªé›¶å¼ é‡ã€‚")
            image = torch.zeros(3, IMG_SIZE, IMG_SIZE)
            tabular_features = torch.zeros(self.num_tabular_features)
            target_value = torch.tensor([0.0])
            return image, tabular_features, target_value

        tabular_features = torch.tensor(self.tabular_data[idx], dtype=torch.float32)
        target_value = torch.tensor([self.target_values[idx]], dtype=torch.float32)

        if self.transform:
            image = self.transform(image)

        return image, tabular_features, target_value


# ===================================================================
# 3. æ–°çš„å¤šæ¨¡æ€æ¨¡å‹å®šä¹‰ (åæœŸèåˆç­–ç•¥)
# ===================================================================
class LateFusionMultiModalNet(nn.Module):
    """ä¸€ä¸ªé€šç”¨çš„â€œåæœŸèåˆâ€å¤šæ¨¡æ€ç½‘ç»œã€‚ å®ƒæ¥æ”¶ä¸€ä¸ªå®Œæ•´çš„å›¾åƒå›å½’æ¨¡å‹ä½œä¸ºå›¾åƒåˆ†æ”¯ã€‚."""

    def __init__(self, image_regression_model, num_tabular_features, hidden_dim=64, dropout_rate=0.5):
        super().__init__()
        # å›¾åƒåˆ†æ”¯ï¼šç›´æ¥ä½¿ç”¨æ‚¨ä¼ å…¥çš„ã€å®Œæ•´çš„ã€ç«¯åˆ°ç«¯çš„å›¾åƒå›å½’æ¨¡å‹
        self.image_branch = image_regression_model

        # è¡¨æ ¼æ•°æ®åˆ†æ”¯ (MLP)
        self.tabular_branch = nn.Sequential(
            nn.Linear(num_tabular_features, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(hidden_dim, hidden_dim // 2),
        )

        # èåˆä¸å›å½’å¤´
        # è¾“å…¥ç»´åº¦ = å›¾åƒåˆ†æ”¯çš„è¾“å‡º(1) + è¡¨æ ¼åˆ†æ”¯çš„è¾“å‡º(hidden_dim // 2)
        fusion_input_dim = 1 + (hidden_dim // 2)
        self.fusion_head = nn.Sequential(
            nn.Linear(fusion_input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1),  # æœ€ç»ˆè¾“å‡ºä¸€ä¸ªå›å½’å€¼
        )

    def forward(self, image, tabular_data):
        # 1. å›¾åƒåˆ†æ”¯ç›´æ¥äº§ç”Ÿä¸€ä¸ªå›å½’é¢„æµ‹å€¼
        image_output = self.image_branch(image)  # Shape: [batch, 1]

        # 2. æå–è¡¨æ ¼ç‰¹å¾
        tabular_features = self.tabular_branch(tabular_data)  # Shape: [batch, 32]

        # 3. æ‹¼æ¥èåˆï¼šå°†å›¾åƒçš„é¢„æµ‹å€¼å’Œè¡¨æ ¼ç‰¹å¾æ‹¼æ¥
        combined_features = torch.cat([image_output, tabular_features], dim=1)  # Shape: [batch, 33]

        # 4. æœ€ç»ˆå†³ç­–
        final_output = self.fusion_head(combined_features)
        return final_output


# ===================================================================
# 4. åŸå§‹çš„å›¾åƒå›å½’æ¨¡å‹å·¥å‚ (å®Œå…¨éµå¾ªæ‚¨çš„ä»£ç )
# ===================================================================
def create_regression_model(model_name: str):
    """æ ¹æ®æ¨¡å‹åç§°ï¼Œåˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªä¿®æ”¹å¥½ç”¨äºå›å½’çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚."""
    print(f"--- æ­£åœ¨åˆ›å»ºå›¾åƒå›å½’æ¨¡å‹: {model_name} ---")

    # æ–¹æ¡ˆAï¼šä½¿ç”¨ torchvision åŠ è½½ç»å…¸æ¨¡å‹
    if model_name == "resnet50":
        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, 1)

    elif model_name == "vgg16":
        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)
        num_ftrs = model.classifier[6].in_features
        model.classifier[6] = nn.Linear(num_ftrs, 1)

    elif model_name == "densenet121":
        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)
        num_ftrs = model.classifier.in_features
        model.classifier = nn.Linear(num_ftrs, 1)

    elif model_name == "mobilenet_v3_large":
        model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V2)
        num_ftrs = model.classifier[3].in_features
        model.classifier[3] = nn.Linear(num_ftrs, 1)

    # æ–¹æ¡ˆBï¼šä½¿ç”¨ timm åŠ è½½æ›´å¤šã€æ›´ç°ä»£çš„æ¨¡å‹ (æ›´æ¨è)
    elif any(name in model_name for name in ["efficientnet", "vit", "resnext", "swin", "convnext"]):
        model = timm.create_model(model_name, pretrained=True, num_classes=1)

    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹åç§°: {model_name}")

    return model


# ===================================================================
# 5. é€šç”¨è®­ç»ƒå‡½æ•° (å·²æ”¹é€ , æ—¥å¿—è®°å½•æ›´ç¨³å¥)
# ===================================================================
def run_training_session(model, model_name, train_loader, val_loader, save_dir):
    """å¯¹ç»™å®šçš„å¤šæ¨¡æ€æ¨¡å‹æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒå’ŒéªŒè¯æµç¨‹ã€‚."""
    model.to(DEVICE)
    print(f"æ¨¡å‹ '{model_name}' å·²ç§»è‡³è®¾å¤‡: {DEVICE}")

    criterion = nn.MSELoss()
    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, "min", patience=10, factor=0.5, verbose=True)

    best_val_loss = float("inf")

    # --- å…³é”®ä¿®æ”¹ï¼šåœ¨è®­ç»ƒå¼€å§‹å‰ï¼Œå…ˆæ¸…ç©ºæˆ–åˆ›å»ºæ—¥å¿—æ–‡ä»¶ ---
    log_files = {
        "train_losses": os.path.join(save_dir, "train_losses.txt"),
        "val_losses": os.path.join(save_dir, "val_losses.txt"),
        "val_maes": os.path.join(save_dir, "val_maes.txt"),
        "val_r2s": os.path.join(save_dir, "val_r2s.txt"),
    }
    for file_path in log_files.values():
        with open(file_path, "w") as f:
            pass  # åˆ›å»ºæˆ–æ¸…ç©ºæ–‡ä»¶

    for epoch in range(EPOCHS):
        model.train()
        running_loss = 0.0
        train_pbar = tqdm(train_loader, desc=f"æ¨¡å‹: {model_name} | Epoch {epoch + 1}/{EPOCHS} [è®­ç»ƒ]")

        for images, tabular, labels in train_pbar:
            images, tabular, labels = images.to(DEVICE), tabular.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(images, tabular)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            train_pbar.set_postfix({"loss": f"{loss.item():.4f}"})

        avg_train_loss = running_loss / len(train_loader)

        model.eval()
        val_loss, all_preds, all_labels = 0.0, [], []
        with torch.no_grad():
            for images, tabular, labels in val_loader:
                images, tabular, labels = images.to(DEVICE), tabular.to(DEVICE), labels.to(DEVICE)
                outputs = model(images, tabular)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                all_preds.extend(outputs.cpu().numpy().flatten())
                all_labels.extend(labels.cpu().numpy().flatten())

        avg_val_loss = val_loss / len(val_loader)
        val_mae = mean_absolute_error(all_labels, all_preds)
        val_r2 = r2_score(all_labels, all_preds)

        print(
            f"ç»“æœ -> è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | éªŒè¯æŸå¤±: {avg_val_loss:.4f} | éªŒè¯MAE: {val_mae:.4f} | éªŒè¯R2: {val_r2:.4f}"
        )

        # --- å…³é”®ä¿®æ”¹ï¼šåœ¨æ¯ä¸ªepochç»“æŸåï¼Œç«‹å³å°†ç»“æœè¿½åŠ å†™å…¥æ–‡ä»¶ ---
        with open(log_files["train_losses"], "a") as f:
            f.write(f"{avg_train_loss}\n")
        with open(log_files["val_losses"], "a") as f:
            f.write(f"{avg_val_loss}\n")
        with open(log_files["val_maes"], "a") as f:
            f.write(f"{val_mae}\n")
        with open(log_files["val_r2s"], "a") as f:
            f.write(f"{val_r2}\n")

        scheduler.step(avg_val_loss)

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), os.path.join(save_dir, "best.pt"))
            print(f"ğŸ‰ æ¨¡å‹ {model_name} å‘ç°æ–°çš„æœ€ä½³æƒé‡, éªŒè¯æŸå¤±: {best_val_loss:.4f}")

    print(f"\næ¨¡å‹ {model_name} è®­ç»ƒå®Œæˆï¼")


# ===================================================================
# 6. ä¸»æ‰§è¡Œå™¨ (å·²æ”¹é€ )
# ===================================================================
if __name__ == "__main__":
    # ğŸš€ åœ¨è¿™é‡Œå®šä¹‰æ‚¨æƒ³è¿›è¡Œå¯¹æ¯”å®éªŒçš„æ‰€æœ‰æ¨¡å‹ï¼
    models_to_train = [
        "resnet50",
        # 'efficientnet_b0',
        "convnext_tiny",
        "vit_base_patch16_224",
        # 'swin_tiny_patch4_window7_224',
    ]

    # --- æ•°æ®åŠ è½½ä¸å‡†å¤‡ ---
    train_transform = transforms.Compose(
        [
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    val_transform = transforms.Compose(
        [
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    train_dataset = MultiModalDataset(csv_path=TRAIN_CSV_PATH, project_root=PROJECT_ROOT, transform=train_transform)
    val_dataset = MultiModalDataset(csv_path=VAL_CSV_PATH, project_root=PROJECT_ROOT, transform=val_transform)

    num_tabular_features = train_dataset.num_tabular_features

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)
    print(f"å¤šæ¨¡æ€æ•°æ®åŠ è½½å™¨å·²åˆ›å»ºï¼Œå…±æ£€æµ‹åˆ° {num_tabular_features} ä¸ªè¡¨æ ¼ç‰¹å¾ã€‚å‡†å¤‡å¼€å§‹å®éªŒ...")

    # --- å¾ªç¯æ‰§è¡Œæ‰€æœ‰å®éªŒ ---
    for model_name in models_to_train:
        print(f"\n{'=' * 25} æ­£åœ¨å¼€å§‹æ¨¡å‹: {model_name.upper()} çš„å®éªŒ {'=' * 25}")

        current_save_dir = os.path.join(PROJECT_ROOT, f"runs_multimodal_{model_name}")
        os.makedirs(current_save_dir, exist_ok=True)

        # 1. ä¸¥æ ¼æŒ‰ç…§æ‚¨çš„è¦æ±‚ï¼Œåˆ›å»ºåŸå§‹çš„ã€ç«¯åˆ°ç«¯çš„å›¾åƒå›å½’æ¨¡å‹
        image_regression_model = create_regression_model(model_name)

        # 2. å°†è¿™ä¸ªå›¾åƒå›å½’æ¨¡å‹ä½œä¸ºâ€œå›¾åƒåˆ†æ”¯â€ï¼Œç»„è£…æˆæœ€ç»ˆçš„â€œåæœŸèåˆâ€å¤šæ¨¡æ€æ¨¡å‹
        late_fusion_model = LateFusionMultiModalNet(
            image_regression_model=image_regression_model, num_tabular_features=num_tabular_features
        )

        # (å¯é€‰) æ‰“å°æ¨¡å‹ç»“æ„
        print("\n--- æ¨¡å‹ç»“æ„æ‘˜è¦ ---")
        summary(
            late_fusion_model,
            input_size=[(BATCH_SIZE, 3, IMG_SIZE, IMG_SIZE), (BATCH_SIZE, num_tabular_features)],
            depth=3,
            col_names=["input_size", "output_size", "num_params", "mult_adds"],
        )
        print("---------------------\n")

        # 3. æ‰§è¡Œè®­ç»ƒ
        run_training_session(late_fusion_model, model_name, train_loader, val_loader, current_save_dir)

        del image_regression_model, late_fusion_model
        torch.cuda.empty_cache()

    print("\næ‰€æœ‰å®éªŒå·²å®Œæˆï¼")
