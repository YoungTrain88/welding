# train.py

import os

import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from PIL import Image
from sklearn.metrics import mean_absolute_error, r2_score
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import transforms
from tqdm import tqdm

# ----------------- 1. ä»è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥æ‰€éœ€ç±» -----------------
# ç¡®ä¿å¯ä»¥ä»æˆ‘ä»¬åˆ›å»ºçš„æ¨¡å—ä¸­å¯¼å…¥ RegressionModel
from my_yolo_regression_project1.custom_modules.custom_tasks import RegressionModel

# ä» ultralytics å¯¼å…¥ YOLO ä»¥ä¾¿åŠ è½½æ¨¡å‹ç»“æ„å’Œæƒé‡

# ----------------- 2. å®šä¹‰è¶…å‚æ•°å’Œé…ç½® -----------------
# è·¯å¾„é…ç½®
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
MODEL_YAML_PATH = (
    r"C:\Users\User\Desktop\ç„Šæ¥\ultralytics-main\ultralytics-main\my_yolo_regression_project1\yolov8n-regression.yaml"
)
PRETRAINED_WEIGHTS_PATH = "yolov8n.pt"  # ç¡®ä¿æ­¤æ–‡ä»¶å·²ä¸‹è½½æˆ–å­˜åœ¨
TRAIN_CSV_PATH = (
    r"C:\Users\User\Desktop\ç„Šæ¥\ultralytics-main\ultralytics-main\my_yolo_regression_project1\datasets\train.csv"
)
VAL_CSV_PATH = (
    r"C:\Users\User\Desktop\ç„Šæ¥\ultralytics-main\ultralytics-main\my_yolo_regression_project1\datasets\val.csv"
)
SAVE_DIR = os.path.join(r"my_yolo_regression_project1", "runs")  # ä¿å­˜æ¨¡å‹æƒé‡å’Œç»“æœçš„ç›®å½•

# è®­ç»ƒé…ç½®
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
EPOCHS = 300
BATCH_SIZE = 8
LEARNING_RATE = 1e-4
IMG_SIZE = 224

# ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
os.makedirs(SAVE_DIR, exist_ok=True)


# ----------------- 3. è‡ªå®šä¹‰æ•°æ®é›†ç±» -----------------
class RegressionDataset(Dataset):
    def __init__(self, csv_path, transform=None):
        self.data_frame = pd.read_csv(csv_path)
        self.transform = transform

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        img_relative_path = self.data_frame.iloc[idx, 0]
        img_abs_path = os.path.join(PROJECT_ROOT, "my_yolo_regression_project1", img_relative_path)
        image = Image.open(img_abs_path).convert("RGB")
        value = torch.tensor([self.data_frame.iloc[idx, 1]], dtype=torch.float32)
        if self.transform:
            image = self.transform(image)
        return image, value


# ----------------- 4. ä¸»è®­ç»ƒé€»è¾‘ -----------------
def main():
    print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")

    # --- æ•°æ®åŠ è½½ ---
    transform = transforms.Compose(
        [
            transforms.Resize((IMG_SIZE, IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    train_dataset = RegressionDataset(csv_path=TRAIN_CSV_PATH, transform=transform)
    val_dataset = RegressionDataset(csv_path=VAL_CSV_PATH, transform=transform)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    print("æ•°æ®åŠ è½½å™¨å‡†å¤‡å®Œæ¯•ã€‚")

    # --- æ¨¡å‹åˆå§‹åŒ– ---
    # ----------------------------- æ–°çš„ä¿®æ”¹éƒ¨åˆ†å¼€å§‹ -----------------------------

    # 1. ç›´æ¥å®ä¾‹åŒ–æˆ‘ä»¬è‡ªå·±çš„ RegressionModel
    #    æˆ‘ä»¬ä¸å†ä½¿ç”¨ YOLO() å°è£…ç±»ã€‚è¿™é‡Œçš„ ch=3 è¡¨ç¤ºè¾“å…¥é€šé“ä¸º3 (RGBå›¾ç‰‡)
    print("ç›´æ¥ä» YAML åˆ›å»ºè‡ªå®šä¹‰ RegressionModel...")
    net = RegressionModel(MODEL_YAML_PATH, ch=3).to(DEVICE)

    # 2. åŠ è½½é¢„è®­ç»ƒæƒé‡
    print(f"åŠ è½½é¢„è®­ç»ƒæƒé‡ä»: {PRETRAINED_WEIGHTS_PATH}")

    # åŠ è½½é¢„è®­ç»ƒçš„ .pt æ–‡ä»¶ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŒ…å« state_dict çš„å­—å…¸
    ckpt = torch.load(PRETRAINED_WEIGHTS_PATH, map_location=DEVICE)

    # å°† state_dict åŠ è½½åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­
    # ä½¿ç”¨ strict=False æ˜¯ã€å…³é”®ã€‘
    # è¿™å…è®¸æˆ‘ä»¬åªåŠ è½½é‚£äº›åœ¨ä¸¤ä¸ªæ¨¡å‹ä¸­åç§°å’Œå°ºå¯¸éƒ½åŒ¹é…çš„å±‚ï¼ˆå³éª¨å¹²ç½‘ç»œéƒ¨åˆ†ï¼‰ï¼Œ
    # è€Œå¿½ç•¥ä¸åŒ¹é…çš„å±‚ï¼ˆä¾‹å¦‚æˆ‘ä»¬è‡ªå·±çš„ RegressionHead å’ŒåŸæ¥çš„ Detect Headï¼‰ã€‚
    state_dict = ckpt["model"].float().state_dict()
    net.load_state_dict(state_dict, strict=False)

    print("æ¨¡å‹åŠ è½½å¹¶ç§»åŠ¨åˆ°è®¾å¤‡ã€‚")
    # --- æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ---
    criterion = nn.MSELoss()  # å‡æ–¹è¯¯å·®æŸå¤±ï¼Œå›å½’ä»»åŠ¡é¦–é€‰
    # criterion = nn.L1Loss() # ä¹Ÿå¯ä½¿ç”¨L1æŸå¤± (å¹³å‡ç»å¯¹è¯¯å·®)
    optimizer = optim.AdamW(net.parameters(), lr=LEARNING_RATE)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # æ¯10ä¸ªepochå­¦ä¹ ç‡ä¹˜ä»¥0.5

    # --- è®­ç»ƒå¾ªç¯ ---
    best_val_loss = float("inf")
    train_losses = []
    val_losses = []
    val_maes = []
    val_r2s = []

    for epoch in range(EPOCHS):
        # è®­ç»ƒé˜¶æ®µ
        net.train()
        running_loss = 0.0
        train_pbar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [è®­ç»ƒ]")

        for images, labels in train_pbar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = net(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            train_pbar.set_postfix({"loss": loss.item()})

        avg_train_loss = running_loss / len(train_loader)
        train_losses.append(avg_train_loss)  # è®°å½•è®­ç»ƒæŸå¤±

        # éªŒè¯é˜¶æ®µ
        net.eval()
        val_loss = 0.0
        all_preds = []
        all_labels = []
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [éªŒè¯]")
            for images, labels in val_pbar:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = net(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                val_pbar.set_postfix({"val_loss": loss.item()})
                all_preds.extend(outputs.cpu().numpy().flatten())
                all_labels.extend(labels.cpu().numpy().flatten())

        avg_val_loss = val_loss / len(val_loader)
        val_losses.append(avg_val_loss)

        # è®¡ç®—å›å½’æŒ‡æ ‡
        val_mae = mean_absolute_error(all_labels, all_preds)
        val_r2 = r2_score(all_labels, all_preds)
        val_maes.append(val_mae)
        val_r2s.append(val_r2)

        print(
            f"Epoch {epoch + 1}/{EPOCHS} -> è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | éªŒè¯æŸå¤±: {avg_val_loss:.4f} | éªŒè¯MAE: {val_mae:.4f} | éªŒè¯R2: {val_r2:.4f}"
        )

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()

        # --- ä¿å­˜æ¨¡å‹ ---
        torch.save(net.state_dict(), os.path.join(SAVE_DIR, "last.pt"))

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(net.state_dict(), os.path.join(SAVE_DIR, "best.pt"))
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ŒéªŒè¯æŸå¤±: {best_val_loss:.4f}")

    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ°: {os.path.join(SAVE_DIR, 'best.pt')}")
    # ä¿å­˜æŸå¤±æ›²çº¿ä¸ºtxtæ ¼å¼
    with open(os.path.join(SAVE_DIR, "train_losses.txt"), "w", encoding="utf-8") as f:
        for loss in train_losses:
            f.write(f"{loss}\n")
    with open(os.path.join(SAVE_DIR, "val_losses.txt"), "w", encoding="utf-8") as f:
        for loss in val_losses:
            f.write(f"{loss}\n")
    # ä¿å­˜æŒ‡æ ‡
    with open(os.path.join(SAVE_DIR, "val_maes.txt"), "w", encoding="utf-8") as f:
        for mae in val_maes:
            f.write(f"{mae}\n")
    with open(os.path.join(SAVE_DIR, "val_r2s.txt"), "w", encoding="utf-8") as f:
        for r2 in val_r2s:
            f.write(f"{r2}\n")


if __name__ == "__main__":
    main()
