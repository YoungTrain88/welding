# from ultralytics import YOLO

# # Load a model
# model = YOLO("yolo11n-cls.yaml")  # build a new model from YAML
# model = YOLO("yolo11n-cls.pt")  # load a pretrained model (recommended for training)
# model = YOLO("yolo11n-cls.yaml").load("yolo11n-cls.pt")  # build from YAML and transfer weights

# # Train the model
# results = model.train(data="mnist160", epochs=100, imgsz=64)

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import transforms
from PIL import Image
import pandas as pd
from tqdm import tqdm
from sklearn.metrics import mean_absolute_error, r2_score
import glob

# å¯¼å…¥è‡ªå®šä¹‰-RegressionModel
from my_yolo_r_p1_c_s_att_conv.custom_modules.custom_tasks import RegressionModel

# é…ç½®
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
# MODEL_YAML_PATH = r'C:\Users\User\Desktop\ç„Šæ¥\ultralytics-main\ultralytics-main\my_yolo_r_p1_c_s_att_conv\yoloV11n-r-att-conv.yaml'
# PRETRAINED_WEIGHTS_PATH = 'yolo11n-cls.pt'  # ä½ çš„é¢„è®­ç»ƒæƒé‡
TRAIN_CSV_PATH = os.path.join(PROJECT_ROOT, 'yolo8-12-æ­£åæ‹¼æ¥300è½®', 'datasets', 'train.csv')
VAL_CSV_PATH = os.path.join(PROJECT_ROOT,  'yolo8-12-æ­£åæ‹¼æ¥300è½®','datasets', 'val.csv')
# SAVE_DIR = os.path.join('my_yolo_r_p1_c_s_att_conv', 'runs-yolo11n-AFAR')  # å¯è‡ªå®šä¹‰

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
EPOCHS = 300 #è°ƒæ•´è®­ç»ƒè½®æ•°çœ‹R2èƒ½å¦æœ‰æ‰€æé«˜
BATCH_SIZE = 8
LEARNING_RATE = 1e-4
IMG_SIZE = 224

# os.makedirs(SAVE_DIR, exist_ok=True)

class RegressionDataset(Dataset):
    def __init__(self, csv_path, transform=None):
        self.data_frame = pd.read_csv(csv_path)
        self.transform = transform

    def __len__(self):
        return len(self.data_frame)

    def __getitem__(self, idx):
        img_relative_path = self.data_frame.iloc[idx, 0]
        img_abs_path = os.path.join(PROJECT_ROOT, 'my_yolo_regression_project1-cat-shuffed', img_relative_path)
        image = Image.open(img_abs_path).convert("RGB")
        value = torch.tensor([self.data_frame.iloc[idx, 1]], dtype=torch.float32)
        if self.transform:
            image = self.transform(image)
        return image, value

def train_one_yaml(yaml_path):
    print(f"\n========== å¼€å§‹è®­ç»ƒ: {yaml_path} ==========")
    # ä¿å­˜è·¯å¾„æ”¹ä¸ºyolo8-12-æ­£é¢/runs-xxx
    yaml_name = os.path.splitext(os.path.basename(yaml_path))[0]
    save_dir = os.path.join(PROJECT_ROOT, 'yolo8-12æ­£é¢-300è½®', f"runs-{yaml_name}")
    os.makedirs(save_dir, exist_ok=True)

    # å…¶ä½™é…ç½®å’Œæ•°æ®åŠ è½½ä¸å˜
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    train_dataset = RegressionDataset(csv_path=TRAIN_CSV_PATH, transform=transform)
    val_dataset = RegressionDataset(csv_path=VAL_CSV_PATH, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

    net = RegressionModel(yaml_path, ch=3).to(DEVICE)
    criterion = nn.MSELoss()
    optimizer = optim.AdamW(net.parameters(), lr=LEARNING_RATE)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)

    best_val_loss = float('inf')
    train_losses, val_losses, val_maes, val_r2s = [], [], [], []

    for epoch in range(EPOCHS):
        net.train()
        running_loss = 0.0
        train_pbar = tqdm(train_loader, desc=f"[{yaml_name}] Epoch {epoch+1}/{EPOCHS} [è®­ç»ƒ]")
        for images, labels in train_pbar:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = net(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            train_pbar.set_postfix({'loss': loss.item()})
        avg_train_loss = running_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        net.eval()
        val_loss, all_preds, all_labels = 0.0, [], []
        with torch.no_grad():
            val_pbar = tqdm(val_loader, desc=f"[{yaml_name}] Epoch {epoch+1}/{EPOCHS} [éªŒè¯]")
            for images, labels in val_pbar:
                images, labels = images.to(DEVICE), labels.to(DEVICE)
                outputs = net(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                val_pbar.set_postfix({'val_loss': loss.item()})
                all_preds.extend(outputs.cpu().numpy().flatten())
                all_labels.extend(labels.cpu().numpy().flatten())
        avg_val_loss = val_loss / len(val_loader)
        val_losses.append(avg_val_loss)
        val_mae = mean_absolute_error(all_labels, all_preds)
        val_r2 = r2_score(all_labels, all_preds)
        val_maes.append(val_mae)
        val_r2s.append(val_r2)

        print(f"[{yaml_name}] Epoch {epoch+1}/{EPOCHS} -> è®­ç»ƒæŸå¤±: {avg_train_loss:.4f} | éªŒè¯æŸå¤±: {avg_val_loss:.4f} | éªŒè¯MAE: {val_mae:.4f} | éªŒè¯R2: {val_r2:.4f}")
        scheduler.step()
        torch.save(net.state_dict(), os.path.join(save_dir, 'last.pt'))
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(net.state_dict(), os.path.join(save_dir, 'best.pt'))
            print(f"ğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼ŒéªŒè¯æŸå¤±: {best_val_loss:.4f}")

    # ä¿å­˜lossç­‰
    with open(os.path.join(save_dir, 'train_losses.txt'), 'w', encoding='utf-8') as f:
        for loss in train_losses:
            f.write(f"{loss}\n")
    with open(os.path.join(save_dir, 'val_losses.txt'), 'w', encoding='utf-8') as f:
        for loss in val_losses:
            f.write(f"{loss}\n")
    with open(os.path.join(save_dir, 'val_maes.txt'), 'w', encoding='utf-8') as f:
        for mae in val_maes:
            f.write(f"{mae}\n")
    with open(os.path.join(save_dir, 'val_r2s.txt'), 'w', encoding='utf-8') as f:
        for r2 in val_r2s:
            f.write(f"{r2}\n")

if __name__ == '__main__':
    yaml_dir = os.path.join(PROJECT_ROOT, 'yolo8-12-æ­£é¢', 'yaml')
    yaml_files = glob.glob(os.path.join(yaml_dir, '*.yaml'))
    print(f"å…±æ£€æµ‹åˆ° {len(yaml_files)} ä¸ªyamlæ–‡ä»¶ï¼Œå°†ä¾æ¬¡è®­ç»ƒï¼š")
    for yaml_path in yaml_files:
        train_one_yaml(yaml_path)

