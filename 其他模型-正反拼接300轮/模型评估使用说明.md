# 模型性能验证指南

## 概述
这里提供了两个脚本来验证已训练模型在不同数据集上的性能：

1. **`evaluate_models.py`** - 批量评估多个模型的完整脚本
2. **`quick_evaluate.py`** - 快速评估单个模型的简化脚本

## 使用方法

### 方法1: 批量评估多个模型 (`evaluate_models.py`)

#### 1. 修改配置
```python
class Config:
    # 修改为你的模型权重目录
    MODEL_WEIGHTS_DIR = r'C:\Users\User\Desktop\焊接\ultralytics-main\ultralytics-main\其他模型-正反拼接300轮'
    
    # 修改为新的测试数据集CSV文件
    NEW_DATASET_CSV = r'C:\Users\User\Desktop\焊接\ultralytics-main\ultralytics-main\新数据集\test.csv'
    
    # 修改为新数据集的根目录
    NEW_DATASET_ROOT = r'C:\Users\User\Desktop\焊接\ultralytics-main\ultralytics-main\新数据集'
```

#### 2. 准备测试数据
确保你的测试数据CSV文件格式如下：
```csv
image_path,target_value
images/image1.jpg,5.234
images/image2.jpg,4.567
...
```

#### 3. 运行脚本
```bash
python evaluate_models.py
```

#### 4. 查看结果
脚本会在 `evaluation_results/` 目录下生成：
- 每个模型的预测散点图 (`model_name_predictions.png`)
- 每个模型的误差分布图 (`model_name_errors.png`)
- 模型性能比较表 (`model_comparison.csv`)
- 性能比较图 (`model_comparison.png`)

### 方法2: 快速评估单个模型 (`quick_evaluate.py`)

#### 1. 修改配置参数
```python
MODEL_NAME = 'resnet50'  # 要评估的模型名称
WEIGHT_PATH = r'path\to\your\best.pt'  # 模型权重路径
TEST_CSV = r'path\to\your\test.csv'    # 测试数据CSV
TEST_ROOT = r'path\to\your\test\root'  # 测试数据根目录
```

#### 2. 运行脚本
```bash
python quick_evaluate.py
```

#### 3. 查看结果
- 控制台会显示详细的性能指标
- 生成可视化图表 (`model_name_evaluation.png`)
- 保存详细结果 (`model_name_detailed_results.csv`)

## 评估指标说明

### 主要指标
- **MAE (平均绝对误差)**: 预测值与真实值差的绝对值的平均，越小越好
- **RMSE (均方根误差)**: 预测误差的均方根，对大误差更敏感，越小越好
- **R² (决定系数)**: 模型解释数据变异性的比例，越接近1越好
- **MAPE (平均绝对百分比误差)**: 相对误差的百分比，越小越好

### 性能评判标准
- **优秀**: R² > 0.9, MAE < 0.5, MAPE < 10%
- **良好**: R² > 0.8, MAE < 1.0, MAPE < 15%
- **一般**: R² > 0.6, MAE < 1.5, MAPE < 25%
- **较差**: R² < 0.6, MAE > 1.5, MAPE > 25%

## 常见问题及解决方案

### 1. 权重文件不存在
**问题**: `❌ 权重文件不存在`
**解决**: 确认模型权重路径正确，通常在 `runs_model_name/best.pt`

### 2. 测试数据格式错误
**问题**: CSV文件读取错误
**解决**: 确保CSV文件有 `image_path,target_value` 两列

### 3. 图像文件缺失
**问题**: `⚠️ 警告: 文件不存在`
**解决**: 检查图像路径是否正确，脚本会用黑色图像替代缺失的图像

### 4. 模型结构不匹配
**问题**: 加载权重时出错
**解决**: 确保评估脚本中的模型结构与训练时完全一致

### 5. CUDA内存不足
**问题**: GPU内存不足
**解决**: 减小 `BATCH_SIZE` 或设置 `DEVICE = 'cpu'`

## 不同数据集适用性验证

### 领域适应性评估
1. **同领域不同条件**: 如不同拍摄角度、光照条件的焊接图像
2. **相似领域**: 如从焊接扩展到金属加工的其他应用
3. **跨领域**: 如从工业检测扩展到医学影像

### 数据分布差异处理
1. **目标值范围不同**: 可能需要重新标准化
2. **图像特征差异**: 可能需要重新训练或微调
3. **样本数量差异**: 考虑数据增强或少样本学习

## 模型性能改进建议

### 当性能不佳时
1. **数据预处理**: 确保与训练时一致的预处理流程
2. **领域适应**: 考虑在新数据集上进行微调训练
3. **模型集成**: 使用多个模型的预测结果进行集成
4. **特征工程**: 根据新领域特点调整输入特征

### 模型选择建议
根据评估结果选择最适合新数据集的模型：
- **精度优先**: 选择R²最高的模型
- **鲁棒性优先**: 选择MAE最低的模型
- **效率优先**: 在满足精度要求下选择最轻量的模型

## 使用示例

```python
# 示例：评估ResNet50在新数据集上的性能
# 1. 修改quick_evaluate.py中的配置
MODEL_NAME = 'resnet50'
WEIGHT_PATH = r'runs_resnet50\best.pt'
TEST_CSV = r'new_dataset\test.csv'
TEST_ROOT = r'new_dataset'

# 2. 运行评估
python quick_evaluate.py

# 3. 查看结果
# 控制台输出：MAE: 0.234, RMSE: 0.456, R²: 0.892
# 生成图表：resnet50_evaluation.png
# 详细结果：resnet50_detailed_results.csv
```

这样你就可以系统地评估已训练模型在新数据集上的表现，并根据结果决定是否需要进一步的模型改进或重新训练。
